{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "from gensim.models import Word2Vec\n",
    "from gensim.models.phrases import Phrases, Phraser\n",
    "from nltk.corpus import stopwords\n",
    "stop_words = set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "climate: [('cc', 0.6040445566177368), ('behavioural', 0.5667223334312439), ('transformational', 0.5275135636329651), ('systemic', 0.5159832239151001), ('behavioral', 0.5061660408973694), ('climatic', 0.48612093925476074), ('theory', 0.4787351191043854), ('snrm', 0.44460588693618774), ('changes14', 0.442379355430603), ('behaviour', 0.43425530195236206), ('cis', 0.4311087429523468), ('adapt', 0.42795413732528687), ('glof', 0.41736578941345215), ('transformative', 0.41529393196105957), ('livelihoods', 0.41375717520713806), ('glofs', 0.41179803013801575), ('combine', 0.40862709283828735), ('catalysts', 0.406525194644928), ('strategies', 0.40532392263412476), ('agriculture', 0.40394705533981323), ('compounding', 0.39950883388519287), ('drr', 0.39924854040145874), ('mitigating', 0.3978663384914398), ('innovativedevelopment', 0.3872810900211334), ('mitigate', 0.38679689168930054), ('disaster', 0.38476285338401794), ('coastal', 0.3845866918563843), ('adaptability', 0.38023024797439575), ('adapting', 0.3793134391307831), ('adaptation', 0.37861570715904236)]\n",
      "climate change: [('change', 0.7739070653915405), ('cc', 0.7606278657913208), ('climate', 0.7081663012504578), ('threats', 0.5486392378807068), ('vulnerabilities', 0.5424802303314209), ('glofs', 0.5374335646629333), ('adverse', 0.5309047102928162), ('variability', 0.5206513404846191), ('adapt', 0.5147532820701599), ('climatechange', 0.5100172758102417)]\n"
     ]
    }
   ],
   "source": [
    "# Read data from the 'txt' folder\n",
    "def read_data_from_folder(folder_path):\n",
    "    texts = []\n",
    "    for file in os.listdir(folder_path):\n",
    "        if file.endswith('.txt'):\n",
    "            with open(os.path.join(folder_path, file), 'r', encoding='utf-8') as f:\n",
    "                texts.append(f.read())\n",
    "    return texts\n",
    "\n",
    "# Preprocess the text\n",
    "def preprocess_text(text):\n",
    "    text = re.sub(r'\\W+', ' ', text.lower())\n",
    "    tokens = text.split()\n",
    "    filtered_tokens = [token for token in tokens if token not in stop_words]\n",
    "    return filtered_tokens\n",
    "\n",
    "# Train the Word2Vec model\n",
    "def train_word2vec_model(sentences):\n",
    "    model = Word2Vec(sentences, vector_size=100, window=5, min_count=1, workers=4)\n",
    "    model.train(sentences, total_examples=len(sentences), epochs=10)\n",
    "    return model\n",
    "\n",
    "# Find related words and bigrams\n",
    "def find_related_words_and_bigrams(model, phraser, words_and_bigrams, top_n=20):\n",
    "    for word_or_bigram in words_and_bigrams:\n",
    "        if ' ' in word_or_bigram:\n",
    "            splitted = word_or_bigram.split(' ')\n",
    "            if phraser[splitted] == splitted:\n",
    "                print(f\"Bigram '{word_or_bigram}' not found in the model.\")\n",
    "                continue\n",
    "            else:\n",
    "                word_or_bigram = '_'.join(splitted)\n",
    "        try:\n",
    "            print(f\"\\nRelated words for '{word_or_bigram.replace('_', ' ')}':\")\n",
    "            for word, similarity in model.wv.most_similar(word_or_bigram, topn=top_n):\n",
    "                print(f\"{word.replace('_', ' ')}: {similarity}\")\n",
    "        except KeyError:\n",
    "            print(f\"Word or bigram '{word_or_bigram.replace('_', ' ')}' not found in the model.\")\n",
    "\n",
    "\n",
    "def train_model_from_folder(folder_path):\n",
    "    texts = read_data_from_folder(folder_path)\n",
    "    sentences = [preprocess_text(text) for text in texts]\n",
    "\n",
    "    # Create bigrams and update sentences\n",
    "    phrases = Phrases(sentences, min_count=1, threshold=10)\n",
    "    phraser = Phraser(phrases)\n",
    "    bigram_sentences = [phraser[sentence] for sentence in sentences]\n",
    "\n",
    "    model = train_word2vec_model(bigram_sentences)\n",
    "    return model, phraser\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_path = 'txt'\n",
    "model, phraser = train_model_from_folder(folder_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_words_and_bigrams = ['climate', 'climate change', 'objectives', 'objective']\n",
    "find_related_words_and_bigrams(model, phraser, input_words_and_bigrams)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "df6a8c26971e94b7f8e04ae2b63413e05f265476cd0a3206034812b2c9bc52e3"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
